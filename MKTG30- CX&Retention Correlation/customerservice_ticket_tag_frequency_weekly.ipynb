{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260cce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def panoply_df():  \n",
    "    #add  and a.gorgias_tickets_id=b.id and b.ticket_created_at>= DATEADD(day,-7, GETDATE())\n",
    "    #to end of query when deploy\n",
    "    #query send to panoply\n",
    "    tag_query=\"\"\"select \n",
    "    b.id,\n",
    "    a.value,\n",
    "    b.ticket_created_at\n",
    "    from \"cirkul_database_import\".\"gorgias_tickets_ticket_tags\" a,\"cirkul_database_import\".\"gorgias_tickets\" b\n",
    "    where a.gorgias_tickets_id=b.id and a.gorgias_tickets_id=b.id and b.ticket_created_at>= DATEADD(day,-7, GETDATE())\"\"\"#get the last 7 day\n",
    "    #read the query\n",
    "    tag_df = pd.read_sql_query(tag_query, cnx)\n",
    "    #data preprocessing and clearning\n",
    "    tag_df['ticket_created_at']=pd.to_datetime(tag_df['ticket_created_at']).dt.date\n",
    "    tag_df['value']=tag_df['value'].str.lower()\n",
    "    tag_df['value']=tag_df['value'].str.replace(' ','_')\n",
    "    tag_df['value']=tag_df['value'].str.replace('-','_')\n",
    "    tag_df=tag_df.groupby(['value','ticket_created_at']).size().reset_index()\n",
    "    return tag_df\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "def google_api():\n",
    "    #set the limit for the script on interacte with google api\n",
    "    scope = [\"https://spreadsheets.google.com/feeds\",'https://www.googleapis.com/auth/spreadsheets',\"https://www.googleapis.com/auth/drive.file\",\"https://www.googleapis.com/auth/drive\"]\n",
    "    #provide credit\n",
    "    creds = ServiceAccountCredentials.from_json_keyfile_name(\"##############\", scope)\n",
    "    client = gspread.authorize(creds)\n",
    "    #specific tables\n",
    "    spreadsheetName = \"##############\"\n",
    "    sheetName = \"##############\"  # <--- please set the sheet name here.\n",
    "    #open tables\n",
    "    spreadsheet = client.open(spreadsheetName)\n",
    "    sheet = spreadsheet.worksheet(sheetName)\n",
    "    data = sheet.get_all_records()\n",
    "    tmp_df=pd.DataFrame(data)\n",
    "    #drop duplicates for further use\n",
    "    tmp_df=tmp_df.drop_duplicates(subset=['tag'])\n",
    "    return tmp_df\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "def uploader(df,datatable,if_exists):\n",
    "    #credentials\n",
    "    import custome_credential\n",
    "    POSTGRES_ADDRESS = custome_credential.POSTGRES_ADDRESS\n",
    "    POSTGRES_PORT = custome_credential.POSTGRES_PORT\n",
    "    POSTGRES_USERNAME = custome_credential.POSTGRES_USERNAME\n",
    "    POSTGRES_PASSWORD = custome_credential.POSTGRES_PASSWORD\n",
    "    POSTGRES_DBNAME = custome_credential.POSTGRES_DBNAME\n",
    "    #data base form\n",
    "    postgres_str = ('postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'.\n",
    "                    format(username=POSTGRES_USERNAME, \n",
    "                        password=POSTGRES_PASSWORD, \n",
    "                        ipaddress=POSTGRES_ADDRESS, \n",
    "                        port=POSTGRES_PORT, \n",
    "                        dbname=POSTGRES_DBNAME))\n",
    "    #connect and creat engine\n",
    "    cnx = create_engine(postgres_str)\n",
    "    #inject dataframe to datatable\n",
    "    df.to_sql(datatable, con=cnx, if_exists=if_exists,index=False)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import datetime\n",
    "    if datetime.datetime.today().weekday()==3:#modify to 3 for deployment\n",
    "\n",
    "\n",
    "        import datetime\n",
    "        import logging\n",
    "\n",
    "\n",
    "        import pandas as pd\n",
    "        from dateutil.relativedelta import relativedelta\n",
    "        import numpy as np\n",
    "        import datetime as dt\n",
    "        from datetime import timedelta, datetime\n",
    "        import sqlalchemy\n",
    "        from sqlalchemy import create_engine\n",
    "\n",
    "        import json\n",
    "        import requests\n",
    "        import pandas as pd\n",
    "        from six import string_types\n",
    "        from six.moves.urllib.parse import urlencode, urlunparse  # noqa\n",
    "\n",
    "        from datetime import date\n",
    "        from datetime import timedelta\n",
    "\n",
    "        import gspread\n",
    "        from oauth2client.service_account import ServiceAccountCredentials\n",
    "        from pprint import pprint\n",
    "        from datetime import datetime\n",
    "        \n",
    "        import custome_credential\n",
    "        POSTGRES_ADDRESS = custome_credential.POSTGRES_ADDRESS\n",
    "        POSTGRES_PORT = custome_credential.POSTGRES_PORT\n",
    "        POSTGRES_USERNAME = custome_credential.POSTGRES_USERNAME\n",
    "        POSTGRES_PASSWORD = custome_credential.POSTGRES_PASSWORD\n",
    "        POSTGRES_DBNAME = custome_credential.POSTGRES_DBNAME\n",
    "\n",
    "        postgres_str = ('postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'.format(\n",
    "            username=POSTGRES_USERNAME,\n",
    "            password=POSTGRES_PASSWORD,\n",
    "            ipaddress=POSTGRES_ADDRESS,\n",
    "            port=POSTGRES_PORT,\n",
    "            dbname=POSTGRES_DBNAME))\n",
    "\n",
    "        cnx = create_engine(postgres_str)\n",
    "  \n",
    "        \n",
    "        #call functions and get datatables\n",
    "        google_df=google_api()\n",
    "        tag_df=panoply_df()\n",
    "        #join table\n",
    "        out_df=tag_df.merge(google_df[['tag','type','sub_type','Tag Description']],how='inner',left_on='value',right_on='tag')\n",
    "        #define upload parameters\n",
    "        datatable='######################'\n",
    "        if_exists='append'\n",
    "        #define addition feature for the final table\n",
    "        out_df['update_time']=pd.to_datetime((date.today()).strftime('%Y-%m-%d'))\n",
    "        out_df=out_df.rename(columns={0: 'count'})\n",
    "        out_df=out_df.drop(columns=['tag'])\n",
    "        \n",
    "        uploader(df=out_df,datatable=datatable,if_exists=if_exists)\n",
    "\n",
    "\n",
    "    else:\n",
    "        print('not 5st day of this week')#modify to day of week for deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
