{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "def insta_scrapper(tag_name,date_range,insta_sessionid):\n",
    "    #sessionID unique for different instagrame ID\n",
    "    SESSIONID =insta_sessionid\n",
    "    print(SESSIONID)\n",
    "    #header which specific the machine which applys to the request\n",
    "    headers = {\"user-agent\": \"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Mobile Safari/537.36 Edg/87.0.664.57\",\n",
    "           \"cookie\": f\"sessionid={SESSIONID};\"}\n",
    "    #dynamic linktake hastag name\n",
    "    base_url = f'https://www.instagram.com/explore/tags/{tag_name}/?__a=1'\n",
    "    print(base_url)\n",
    "    #initial empty list\n",
    "    text_list=[] \n",
    "    #initial empty max id which used to flip pages\n",
    "    max_id=False\n",
    "    #loop that scrape each page of the hastag\n",
    "    for i in range(0, 1):\n",
    "        print(i)\n",
    "        #sleep to lower the risk of banned\n",
    "        sleep(random.uniform(1, 3)) \n",
    "        #check whether exist a next_max_id\n",
    "        if max_id:\n",
    "            url = base_url + f\"&next_max_id={max_id}\"\n",
    "        else:\n",
    "            url = base_url\n",
    "        #show which link we are scraping\n",
    "        print(f\"Requesting {url}\")\n",
    "        #extract the information\n",
    "        response = requests.get(url,headers=headers)\n",
    "        print(response)\n",
    "        #convert the json to readable form\n",
    "        response = json.loads(response.text)\n",
    "        #flip to the next page or end\n",
    "        try:\n",
    "            max_id = response['data']['top']['next_max_id']\n",
    "            print(f\"New cursor is {max_id}\")\n",
    "        except KeyError:\n",
    "            print(\"There's no next page!\")\n",
    "            break \n",
    "        #get the recent post information through json structured data \n",
    "        for i in response['data']['recent']['sections']:\n",
    "            #get the inter list of content\n",
    "            inter_list=i['layout_content']['medias']\n",
    "            for j in inter_list:\n",
    "                #get the today date and post date\n",
    "                today = datetime.combine(date.today(), datetime.min.time())\n",
    "                post_date=dt.datetime.fromtimestamp(int(j['media']['caption']['created_at']))\n",
    "                #check whether the post is in date range\n",
    "                if (today-post_date).days<date_range:    \n",
    "                    tmp_list=[]\n",
    "                    tmp_list.append(dt.datetime.fromtimestamp(int(j['media']['caption']['created_at'])).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "                    tmp_list.append(j['media']['user']['username'])\n",
    "                    tmp_list.append('https://www.instagram.com/p/'+j['media']['code']+'/')\n",
    "                    tmp_list.append(j['media']['like_count'])\n",
    "                    tmp_list.append(j['media']['comment_count'])\n",
    "                    print(tmp_list)\n",
    "                    text_list.append(tmp_list)\n",
    "\n",
    "\n",
    "        #get the top post information through json structured data \n",
    "        for i in response['data']['top']['sections']:\n",
    "            #get the inter list of content\n",
    "            inter_list=i['layout_content']['medias']\n",
    "            for j in inter_list:\n",
    "                #get the today date and post date\n",
    "                today = datetime.combine(date.today(), datetime.min.time())\n",
    "                post_date=dt.datetime.fromtimestamp(j['media']['caption']['created_at'])\n",
    "                a=j['media']['caption']['created_at']\n",
    "                #print(post_date,j['media']['caption']['created_at'],type(post_date))\n",
    "                if (today-post_date).days<date_range:    \n",
    "                    tmp_list=[]\n",
    "                    tmp_list.append(dt.datetime.fromtimestamp(int(j['media']['caption']['created_at'])).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "                    tmp_list.append(j['media']['user']['username'])\n",
    "                    tmp_list.append('https://www.instagram.com/p/'+j['media']['code']+'/')\n",
    "                    tmp_list.append(j['media']['like_count'])\n",
    "                    tmp_list.append(j['media']['comment_count'])\n",
    "\n",
    "                    print(tmp_list)\n",
    "                    text_list.append(tmp_list)\n",
    "\n",
    "\n",
    "    #turn the list to numpy then numpy to dataframe\n",
    "    array=np.array(text_list)\n",
    "    array=pd.DataFrame(array,columns=['date', 'id','link','like_count','comment_count'])\n",
    "    #indicate the finish state of function\n",
    "    array=array.astype({'like_count': 'int32','comment_count': 'int32'})\n",
    "    array['date']=pd.to_datetime(array['date'])\n",
    "    print('done')\n",
    "    \n",
    "    return array\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "def uploader(df,datatable,if_exists):\n",
    "    #credentials\n",
    "    import custome_credential\n",
    "    POSTGRES_ADDRESS = custome_credential.POSTGRES_ADDRESS\n",
    "    POSTGRES_PORT = custome_credential.POSTGRES_PORT\n",
    "    POSTGRES_USERNAME = custome_credential.POSTGRES_USERNAME\n",
    "    POSTGRES_PASSWORD = custome_credential.POSTGRES_PASSWORD\n",
    "    POSTGRES_DBNAME = custome_credential.POSTGRES_DBNAME\n",
    "    #data base form\n",
    "    postgres_str = ('postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'.\n",
    "                    format(username=POSTGRES_USERNAME, \n",
    "                        password=POSTGRES_PASSWORD, \n",
    "                        ipaddress=POSTGRES_ADDRESS, \n",
    "                        port=POSTGRES_PORT, \n",
    "                        dbname=POSTGRES_DBNAME))\n",
    "    #connect and creat engine\n",
    "    cnx = create_engine(postgres_str)\n",
    "    #inject dataframe to datatable\n",
    "    df.to_sql(datatable, con=cnx, if_exists=if_exists,index=False)\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import datetime\n",
    "    import logging\n",
    "\n",
    "\n",
    "    #basic package needed\n",
    "    from time import sleep\n",
    "    import random\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    import pandas as pd\n",
    "    import sqlalchemy\n",
    "    import psycopg2\n",
    "    from sqlalchemy import create_engine\n",
    "\n",
    "    from datetime import date, datetime, timedelta\n",
    "\n",
    "    import requests \n",
    "    import json\n",
    "    import datetime as dt\n",
    "    import instagram_session_id\n",
    "    hashtag_list=['###########################']\n",
    "    #call function in a loop and \n",
    "    up_df=pd.DataFrame(columns = ['date','id','link','like_count','comment_count'])\n",
    "    for i in hashtag_list:\n",
    "        out_df=insta_scrapper(tag_name=i,date_range=1,insta_sessionid=random.choice(instagram_session_id.instagram_session_id_list))\n",
    "        datatable='###########################'\n",
    "        if_exists='append'\n",
    "        up_df=pd.concat([up_df,out_df])\n",
    "    #drop duplicate link\n",
    "    up_df=up_df.drop_duplicates(subset=['link'])\n",
    "    uploader(df=up_df,datatable=datatable,if_exists=if_exists)\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
